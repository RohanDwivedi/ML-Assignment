{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE802 ML Assignment\n",
    "## comparative study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.08</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1  F2   F3    F4    F5    F6    F7    F8   F9  F10  ...   F12   F13  F14  \\\n",
       "0   0   0   16  2.02  0.52 -2.35 -1.98 -0.70   85    6  ... -0.07  1.08   15   \n",
       "1   0   0   86 -0.90  2.75  0.14  0.83 -0.06  107    1  ...  0.17  1.06   -8   \n",
       "2   1   1  165  0.73  1.05  0.10  2.57 -1.65   41    5  ...  0.04  0.42   -6   \n",
       "\n",
       "    F15   F16   F17   F18   F19   F20  Class  \n",
       "0 -0.63 -3.49 -1.68  0.02  15.3   NaN   True  \n",
       "1 -1.21  0.34  0.36  0.61  10.1   NaN   True  \n",
       "2 -0.46 -0.62  1.67  2.60  11.0  1.55  False  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Data ##\n",
    "DataFrame = pd.read_csv(\"CE802_Ass_2019_Data.csv\")\n",
    "DataFrame.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>93.20400</td>\n",
       "      <td>-0.065980</td>\n",
       "      <td>-0.037800</td>\n",
       "      <td>0.03994</td>\n",
       "      <td>1.219340</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>38.352000</td>\n",
       "      <td>7.156000</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>0.936420</td>\n",
       "      <td>0.742000</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.385840</td>\n",
       "      <td>-0.073300</td>\n",
       "      <td>-0.083320</td>\n",
       "      <td>9.294200</td>\n",
       "      <td>0.074146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.471403</td>\n",
       "      <td>0.500465</td>\n",
       "      <td>70.32064</td>\n",
       "      <td>1.534023</td>\n",
       "      <td>1.041526</td>\n",
       "      <td>1.04141</td>\n",
       "      <td>1.372958</td>\n",
       "      <td>0.980714</td>\n",
       "      <td>25.331946</td>\n",
       "      <td>16.716295</td>\n",
       "      <td>1.076134</td>\n",
       "      <td>1.014567</td>\n",
       "      <td>0.702435</td>\n",
       "      <td>15.458634</td>\n",
       "      <td>0.982961</td>\n",
       "      <td>1.645632</td>\n",
       "      <td>0.979986</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>5.813214</td>\n",
       "      <td>1.891396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>-4.300000</td>\n",
       "      <td>-2.870000</td>\n",
       "      <td>-2.90000</td>\n",
       "      <td>-2.330000</td>\n",
       "      <td>-3.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.000000</td>\n",
       "      <td>-3.470000</td>\n",
       "      <td>-3.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-3.240000</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>-3.060000</td>\n",
       "      <td>-3.190000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-5.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>-1.102500</td>\n",
       "      <td>-0.792500</td>\n",
       "      <td>-0.67000</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.702500</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>-9.250000</td>\n",
       "      <td>-0.615000</td>\n",
       "      <td>-0.802500</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.742500</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>-0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.25000</td>\n",
       "      <td>1.042500</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.335000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>1.505000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>338.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.22000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>6.130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1          F2         F3          F4          F5         F6  \\\n",
       "count  500.000000  500.000000  500.00000  500.000000  500.000000  500.00000   \n",
       "mean     0.668000    0.506000   93.20400   -0.065980   -0.037800    0.03994   \n",
       "std      0.471403    0.500465   70.32064    1.534023    1.041526    1.04141   \n",
       "min      0.000000    0.000000    3.00000   -4.300000   -2.870000   -2.90000   \n",
       "25%      0.000000    0.000000   37.00000   -1.102500   -0.792500   -0.67000   \n",
       "50%      1.000000    1.000000   79.00000   -0.105000   -0.030000    0.03000   \n",
       "75%      1.000000    1.000000  135.25000    1.042500    0.640000    0.76000   \n",
       "max      1.000000    1.000000  338.00000    3.900000    3.300000    3.22000   \n",
       "\n",
       "               F7          F8          F9         F10         F11         F12  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     1.219340   -0.046900   38.352000    7.156000   -0.000580   -0.004480   \n",
       "std      1.372958    0.980714   25.331946   16.716295    1.076134    1.014567   \n",
       "min     -2.330000   -3.230000    0.000000  -49.000000   -3.470000   -3.570000   \n",
       "25%      0.297500   -0.690000   18.000000   -5.000000   -0.750000   -0.702500   \n",
       "50%      1.235000   -0.080000   35.000000    7.000000    0.010000    0.025000   \n",
       "75%      2.080000    0.592500   54.000000   19.000000    0.792500    0.680000   \n",
       "max      5.690000    2.700000  140.000000   61.000000    3.900000    3.030000   \n",
       "\n",
       "              F13         F14         F15         F16         F17         F18  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.936420    0.742000    0.004500    0.385840   -0.073300   -0.083320   \n",
       "std      0.702435   15.458634    0.982961    1.645632    0.979986    0.999405   \n",
       "min      0.000000  -41.000000   -3.240000   -4.080000   -3.060000   -3.190000   \n",
       "25%      0.347500   -9.250000   -0.615000   -0.802500   -0.730000   -0.742500   \n",
       "50%      0.790000    0.000000   -0.005000    0.385000   -0.120000   -0.100000   \n",
       "75%      1.335000   12.000000    0.662500    1.505000    0.560000    0.602500   \n",
       "max      4.000000   55.000000    3.260000    5.680000    2.620000    3.640000   \n",
       "\n",
       "              F19         F20  \n",
       "count  500.000000  328.000000  \n",
       "mean     9.294200    0.074146  \n",
       "std      5.813214    1.891396  \n",
       "min      0.500000   -5.350000  \n",
       "25%      5.100000   -0.740000  \n",
       "50%      8.200000    0.170000  \n",
       "75%     11.800000    0.910000  \n",
       "max     36.800000    6.130000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## statistics of the training dataset ##\n",
    "DataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1995e3d0748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Values missing in F20 Row ##\n",
    "## Data is not normalised ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    279\n",
      "True     221\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1995eb510c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(DataFrame.Class.value_counts())\n",
    "DataFrame.Class.value_counts().plot(kind = 'bar', title = 'class balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data skewed towards False class ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUNED  DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pruned Decision Tree ##\n",
    "\n",
    "def Dec_tree(x,y):\n",
    "    \n",
    "    ''' train optimised decision tree using grid search and \n",
    "    return mean accuracy using stratified K fold cross validation'''\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state = 42)   \n",
    "    \n",
    "    path = clf.cost_complexity_pruning_path(x, y) \n",
    "    \n",
    "    ccp_alphas = np.ndarray.tolist(path.ccp_alphas)                                                        \n",
    "   \n",
    "    max_depth = list(range(3,30,1))                  \n",
    "    \n",
    "    parameter_grid = {'ccp_alpha':ccp_alphas,\n",
    "                      'criterion': ['gini', 'entropy'],\n",
    "                      'splitter': ['best', 'random'],\n",
    "                      'max_depth': max_depth }\n",
    "    \n",
    "    \n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               refit='false',\n",
    "                               param_grid=parameter_grid,  \n",
    "                               n_jobs = -1) \n",
    "    \n",
    "    grid_search.fit(x,y) \n",
    "    \n",
    "    print('Mean cross validated accuracy of the best estimator: {} \\n'.format(grid_search.best_score_))\n",
    "    \n",
    "    best_model = grid_search.best_estimator_              \n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  No F20 Feature ## Baseline Approach ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6076305220883536 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.01089020397884663, class_weight=None,\n",
      "                       criterion='entropy', max_depth=8, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=42,\n",
      "                       splitter='random')\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.53      0.56        80\n",
      "        True       0.45      0.52      0.48        60\n",
      "\n",
      "    accuracy                           0.52       140\n",
      "   macro avg       0.52      0.52      0.52       140\n",
      "weighted avg       0.53      0.52      0.52       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.04089979550102252 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[42 38]\n",
      " [29 31]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()                                     \n",
    "df = df.drop(columns = ['F20'])      \n",
    "\n",
    "data = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(data, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal.values.reshape(-1, 19))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building decision tree and model evaluation ##\n",
    "\n",
    "best_model = Dec_tree(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6508605851979345 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.00929108485499463, class_weight=None,\n",
      "                       criterion='entropy', max_depth=12, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=42,\n",
      "                       splitter='random')\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.53      0.50        64\n",
      "        True       0.57      0.51      0.54        76\n",
      "\n",
      "    accuracy                           0.52       140\n",
      "   macro avg       0.52      0.52      0.52       140\n",
      "weighted avg       0.53      0.52      0.52       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.0440277211577661 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[34 30]\n",
      " [37 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.mean(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building decision tree and model evaluation ##\n",
    "\n",
    "best_model = Dec_tree(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6603557085484796 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.008851674641148326, class_weight=None,\n",
      "                       criterion='entropy', max_depth=15, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=42,\n",
      "                       splitter='random')\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.58      0.59        74\n",
      "        True       0.55      0.58      0.56        66\n",
      "\n",
      "    accuracy                           0.58       140\n",
      "   macro avg       0.58      0.58      0.58       140\n",
      "weighted avg       0.58      0.58      0.58       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.15645424836601296 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[43 31]\n",
      " [28 38]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.median(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building decision tree and model evaluation ##\n",
    "\n",
    "best_model = Dec_tree(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Iterative Imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6696213425129087 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0109252867221733, class_weight=None,\n",
      "                       criterion='gini', max_depth=5, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=42, splitter='best')\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.72      0.73        74\n",
      "        True       0.70      0.73      0.71        66\n",
      "\n",
      "    accuracy                           0.72       140\n",
      "   macro avg       0.72      0.72      0.72       140\n",
      "weighted avg       0.72      0.72      0.72       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.4424019607843137 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[53 21]\n",
      " [18 48]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) \n",
    "x = imp.fit_transform(df.values)  \n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building decision tree and model evaluation ##\n",
    "\n",
    "best_model = Dec_tree(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6388984509466438 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.005103668261562998, class_weight=None,\n",
      "                       criterion='gini', max_depth=7, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=42, splitter='best')\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.64      0.58        59\n",
      "        True       0.70      0.59      0.64        81\n",
      "\n",
      "    accuracy                           0.61       140\n",
      "   macro avg       0.62      0.62      0.61       140\n",
      "weighted avg       0.63      0.61      0.62       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.23029932803909592 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[38 21]\n",
      " [33 48]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame.copy()          \n",
    "\n",
    "z = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = z, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building decision tree and model evaluation ##\n",
    "\n",
    "best_model = Dec_tree(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes (data, target, xtest, ytest):\n",
    "    \n",
    "    clf = GaussianNB() \n",
    "    clf.fit(data,target)\n",
    "    \n",
    "    score = cross_val_score(clf,data,target,cv = 10)\n",
    "    \n",
    "    print('Mean cross validated Accuracy of the model: {}'.format(np.mean(score)))  \n",
    "    \n",
    "    yPred = clf.predict(xtest)\n",
    "\n",
    "    print(\" \\n Classification report: \\n\")  \n",
    "    print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "    print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "    print(\"Confusion Matrix: \\n\" ) \n",
    "    print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No F20 Feature ## Baseline Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated Accuracy of the model: 0.5432636469221835\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.58      0.59        72\n",
      "        True       0.57      0.57      0.57        68\n",
      "\n",
      "    accuracy                           0.58       140\n",
      "   macro avg       0.58      0.58      0.58       140\n",
      "weighted avg       0.58      0.58      0.58       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.15679869334422214 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[42 30]\n",
      " [29 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()                                     \n",
    "df = df.drop(columns = ['F20'])      \n",
    "\n",
    "data = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(data, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal.values.reshape(-1, 19))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building Naive Bayes Classifier and model evaluation ##\n",
    "\n",
    "NaiveBayes(xtrain, ytrain, xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated Accuracy of the model: 0.5337398373983739\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.60      0.62        75\n",
      "        True       0.57      0.60      0.58        65\n",
      "\n",
      "    accuracy                           0.60       140\n",
      "   macro avg       0.60      0.60      0.60       140\n",
      "weighted avg       0.60      0.60      0.60       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.1991828396322779 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[45 30]\n",
      " [26 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.mean(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building Naive Bayes Classifier and model evaluation ##\n",
    "\n",
    "NaiveBayes(xtrain, ytrain, xtest, ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated Accuracy of the model: 0.5337398373983739\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.59      0.61        74\n",
      "        True       0.57      0.59      0.58        66\n",
      "\n",
      "    accuracy                           0.59       140\n",
      "   macro avg       0.59      0.59      0.59       140\n",
      "weighted avg       0.59      0.59      0.59       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.18504901960784303 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[44 30]\n",
      " [27 39]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.median(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building Naive Bayes Classifier and model evaluation ##\n",
    "\n",
    "NaiveBayes(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Iterative Imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated Accuracy of the model: 0.5622531939605111\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.64      0.66        77\n",
      "        True       0.59      0.65      0.62        63\n",
      "\n",
      "    accuracy                           0.64       140\n",
      "   macro avg       0.64      0.64      0.64       140\n",
      "weighted avg       0.65      0.64      0.64       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.28469241773962806 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[49 28]\n",
      " [22 41]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) \n",
    "x = imp.fit_transform(df.values)  \n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building Naive Bayes Classifier and model evaluation ##\n",
    "\n",
    "NaiveBayes(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated Accuracy of the model: 0.5408246225319395\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.58      0.61        77\n",
      "        True       0.54      0.59      0.56        63\n",
      "\n",
      "    accuracy                           0.59       140\n",
      "   macro avg       0.59      0.59      0.58       140\n",
      "weighted avg       0.59      0.59      0.59       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.1702432045779686 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[45 32]\n",
      " [26 37]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame.copy()          \n",
    "\n",
    "z = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = z, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building Naive Bayes Classifier and model evaluation ##\n",
    "\n",
    "\n",
    "NaiveBayes(xtrain, ytrain, xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM (data, target):\n",
    "    clf = svm.SVC(gamma=0.01, C=10, random_state = 42)\n",
    "    \n",
    "    parameter_grid = {'C': np.logspace(-1, 3, 9),\n",
    "                      'gamma': np.logspace(-7, -0, 8)}\n",
    "    \n",
    "    grid_search = GridSearchCV(clf,\n",
    "                               refit='false',\n",
    "                               param_grid=parameter_grid,  \n",
    "                               n_jobs = -1) \n",
    "    \n",
    "    grid_search.fit(data, target) \n",
    "    \n",
    "    print('Mean cross validated accuracy of the best estimator: {} \\n'.format(grid_search.best_score_))\n",
    "    \n",
    "    best_model = grid_search.best_estimator_              \n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  No F20 Feature ## Baseline Approach ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6746701090074584 \n",
      "\n",
      "SVC(C=31.622776601683793, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.66      0.66        71\n",
      "        True       0.65      0.65      0.65        69\n",
      "\n",
      "    accuracy                           0.66       140\n",
      "   macro avg       0.66      0.66      0.66       140\n",
      "weighted avg       0.66      0.66      0.66       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.31414574402939366 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[47 24]\n",
      " [24 45]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()                                     \n",
    "df = df.drop(columns = ['F20'])      \n",
    "\n",
    "data = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(data, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal.values.reshape(-1, 19))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building SVM and model evaluation ##\n",
    "\n",
    "best_model = SVM(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6890131956397016 \n",
      "\n",
      "SVC(C=316.22776601683796, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.70      0.67        64\n",
      "        True       0.72      0.66      0.69        76\n",
      "\n",
      "    accuracy                           0.68       140\n",
      "   macro avg       0.68      0.68      0.68       140\n",
      "weighted avg       0.68      0.68      0.68       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.3579290664492458 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[45 19]\n",
      " [26 50]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.mean(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building SVM and model evaluation ##\n",
    "\n",
    "best_model = SVM(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6914228341939185 \n",
      "\n",
      "SVC(C=316.22776601683796, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.71      0.67        63\n",
      "        True       0.74      0.66      0.70        77\n",
      "\n",
      "    accuracy                           0.69       140\n",
      "   macro avg       0.69      0.69      0.69       140\n",
      "weighted avg       0.69      0.69      0.69       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.37232524964336655 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[45 18]\n",
      " [26 51]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "data = df.fillna(df.F20.median(), inplace=True) \n",
    "\n",
    "x = df.drop(columns=['Class'])                        \n",
    "target = df.Class                \n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building SVM tree and model evaluation ##\n",
    "\n",
    "best_model = SVM(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.8300917957544464 \n",
      "\n",
      "SVC(C=1000.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.84      0.86        74\n",
      "        True       0.83      0.86      0.84        66\n",
      "\n",
      "    accuracy                           0.85       140\n",
      "   macro avg       0.85      0.85      0.85       140\n",
      "weighted avg       0.85      0.85      0.85       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.6997549019607843 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[62 12]\n",
      " [ 9 57]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## preprocessing steps##\n",
    "\n",
    "df = DataFrame.copy()          \n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) \n",
    "x = imp.fit_transform(df.values)  \n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building SVM and model evaluation ##\n",
    "\n",
    "best_model = SVM(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validated accuracy of the best estimator: 0.6962707974756167 \n",
      "\n",
      "SVC(C=316.22776601683796, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      " \n",
      " Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.73      0.70        66\n",
      "        True       0.74      0.69      0.71        74\n",
      "\n",
      "    accuracy                           0.71       140\n",
      "   macro avg       0.71      0.71      0.71       140\n",
      "weighted avg       0.71      0.71      0.71       140\n",
      "\n",
      "\n",
      "Kappa Score: 0.41476345840130513 \n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[48 18]\n",
      " [23 51]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame.copy()          \n",
    "\n",
    "z = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = z, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "\n",
    "x = pd.DataFrame(x).drop(columns = [20])              \n",
    "target = df.Class\n",
    "\n",
    "smote_balance = SMOTE(random_state = 42)                   \n",
    "x_bal, y_bal = smote_balance.fit_sample(x, target) \n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_bal = scaler.fit_transform(x_bal)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_bal, y_bal, random_state = 42)\n",
    "\n",
    "\n",
    "'''*********************************************************************************************'''\n",
    "## building SVM and model evaluation ##\n",
    "\n",
    "best_model = SVM(xtrain, ytrain)\n",
    "\n",
    "print(best_model)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "\n",
    "yPred = best_model.predict(xtest)\n",
    "\n",
    "print(\" \\n Classification report: \\n\")  \n",
    "print(metrics.classification_report(yPred,ytest)  + \"\\n\") \n",
    "print(\"Kappa Score: {} \\n\".format (metrics.cohen_kappa_score(yPred, ytest))) \n",
    "print(\"Confusion Matrix: \\n\" ) \n",
    "print(\"{} \\n\".format (metrics.confusion_matrix(yPred,ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
