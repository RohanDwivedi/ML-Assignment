{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE802 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.08</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1  F2   F3    F4    F5    F6    F7    F8   F9  F10  ...   F12   F13  F14  \\\n",
       "0   0   0   16  2.02  0.52 -2.35 -1.98 -0.70   85    6  ... -0.07  1.08   15   \n",
       "1   0   0   86 -0.90  2.75  0.14  0.83 -0.06  107    1  ...  0.17  1.06   -8   \n",
       "2   1   1  165  0.73  1.05  0.10  2.57 -1.65   41    5  ...  0.04  0.42   -6   \n",
       "\n",
       "    F15   F16   F17   F18   F19   F20  Class  \n",
       "0 -0.63 -3.49 -1.68  0.02  15.3   NaN   True  \n",
       "1 -1.21  0.34  0.36  0.61  10.1   NaN   True  \n",
       "2 -0.46 -0.62  1.67  2.60  11.0  1.55  False  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data from csv file as data\n",
    "data = pd.read_csv(\"CE802_Ass_2019_Data.csv\")\n",
    "data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>93.20400</td>\n",
       "      <td>-0.065980</td>\n",
       "      <td>-0.037800</td>\n",
       "      <td>0.03994</td>\n",
       "      <td>1.219340</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>38.352000</td>\n",
       "      <td>7.156000</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>0.936420</td>\n",
       "      <td>0.742000</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.385840</td>\n",
       "      <td>-0.073300</td>\n",
       "      <td>-0.083320</td>\n",
       "      <td>9.294200</td>\n",
       "      <td>0.074146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.471403</td>\n",
       "      <td>0.500465</td>\n",
       "      <td>70.32064</td>\n",
       "      <td>1.534023</td>\n",
       "      <td>1.041526</td>\n",
       "      <td>1.04141</td>\n",
       "      <td>1.372958</td>\n",
       "      <td>0.980714</td>\n",
       "      <td>25.331946</td>\n",
       "      <td>16.716295</td>\n",
       "      <td>1.076134</td>\n",
       "      <td>1.014567</td>\n",
       "      <td>0.702435</td>\n",
       "      <td>15.458634</td>\n",
       "      <td>0.982961</td>\n",
       "      <td>1.645632</td>\n",
       "      <td>0.979986</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>5.813214</td>\n",
       "      <td>1.891396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>-4.300000</td>\n",
       "      <td>-2.870000</td>\n",
       "      <td>-2.90000</td>\n",
       "      <td>-2.330000</td>\n",
       "      <td>-3.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.000000</td>\n",
       "      <td>-3.470000</td>\n",
       "      <td>-3.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-3.240000</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>-3.060000</td>\n",
       "      <td>-3.190000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-5.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>-1.102500</td>\n",
       "      <td>-0.792500</td>\n",
       "      <td>-0.67000</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.702500</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>-9.250000</td>\n",
       "      <td>-0.615000</td>\n",
       "      <td>-0.802500</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.742500</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>-0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.25000</td>\n",
       "      <td>1.042500</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>2.080000</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.335000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>1.505000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>338.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.22000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>6.130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1          F2         F3          F4          F5         F6  \\\n",
       "count  500.000000  500.000000  500.00000  500.000000  500.000000  500.00000   \n",
       "mean     0.668000    0.506000   93.20400   -0.065980   -0.037800    0.03994   \n",
       "std      0.471403    0.500465   70.32064    1.534023    1.041526    1.04141   \n",
       "min      0.000000    0.000000    3.00000   -4.300000   -2.870000   -2.90000   \n",
       "25%      0.000000    0.000000   37.00000   -1.102500   -0.792500   -0.67000   \n",
       "50%      1.000000    1.000000   79.00000   -0.105000   -0.030000    0.03000   \n",
       "75%      1.000000    1.000000  135.25000    1.042500    0.640000    0.76000   \n",
       "max      1.000000    1.000000  338.00000    3.900000    3.300000    3.22000   \n",
       "\n",
       "               F7          F8          F9         F10         F11         F12  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     1.219340   -0.046900   38.352000    7.156000   -0.000580   -0.004480   \n",
       "std      1.372958    0.980714   25.331946   16.716295    1.076134    1.014567   \n",
       "min     -2.330000   -3.230000    0.000000  -49.000000   -3.470000   -3.570000   \n",
       "25%      0.297500   -0.690000   18.000000   -5.000000   -0.750000   -0.702500   \n",
       "50%      1.235000   -0.080000   35.000000    7.000000    0.010000    0.025000   \n",
       "75%      2.080000    0.592500   54.000000   19.000000    0.792500    0.680000   \n",
       "max      5.690000    2.700000  140.000000   61.000000    3.900000    3.030000   \n",
       "\n",
       "              F13         F14         F15         F16         F17         F18  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
       "mean     0.936420    0.742000    0.004500    0.385840   -0.073300   -0.083320   \n",
       "std      0.702435   15.458634    0.982961    1.645632    0.979986    0.999405   \n",
       "min      0.000000  -41.000000   -3.240000   -4.080000   -3.060000   -3.190000   \n",
       "25%      0.347500   -9.250000   -0.615000   -0.802500   -0.730000   -0.742500   \n",
       "50%      0.790000    0.000000   -0.005000    0.385000   -0.120000   -0.100000   \n",
       "75%      1.335000   12.000000    0.662500    1.505000    0.560000    0.602500   \n",
       "max      4.000000   55.000000    3.260000    5.680000    2.620000    3.640000   \n",
       "\n",
       "              F19         F20  \n",
       "count  500.000000  328.000000  \n",
       "mean     9.294200    0.074146  \n",
       "std      5.813214    1.891396  \n",
       "min      0.500000   -5.350000  \n",
       "25%      5.100000   -0.740000  \n",
       "50%      8.200000    0.170000  \n",
       "75%     11.800000    0.910000  \n",
       "max     36.800000    6.130000  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarty statistics for the data (data analysis)\n",
    "data.drop(columns = ['Class']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    279\n",
      "True     221\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18b3d283548>"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check class balance (data analysis)\n",
    "print(data.Class.value_counts())\n",
    "data.Class.value_counts().plot(kind = 'bar', title = 'class balance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruned Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See https://medium.com/@haydar_ai/learning-data-science-day-22-cross-validation-and-parameter-tuning-b14bcbc6b012\n",
    "\n",
    "def Build_tree(x,y):\n",
    "    clf = DecisionTreeClassifier(random_state = 42)   \n",
    "    path = clf.cost_complexity_pruning_path(x, y) \n",
    "    ccp_alphas = np.ndarray.tolist(path.ccp_alphas)                                                        \n",
    "    max_depth = list(range(1,30,1))     \n",
    "    parameter_grid = {'ccp_alpha':ccp_alphas,\n",
    "                      'criterion': ['gini', 'entropy'],\n",
    "                      'splitter': ['best', 'random'],\n",
    "                      'max_depth': max_depth }\n",
    "    cross_validation = StratifiedKFold(n_splits=10) \n",
    "    grid_search = GridSearchCV(clf, param_grid=parameter_grid, cv=cross_validation, n_jobs = -1) \n",
    "    grid_search.fit(x,y)                           \n",
    "    print('Average Accuracy of the model: {}'.format(grid_search.best_score_))  \n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    clf = grid_search.best_estimator_              \n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building pruned decision tree 'without F20 feature'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Average Accuracy of the model: 0.6578231292517006\n",
      "Best parameters: {'ccp_alpha': 0.0, 'criterion': 'entropy', 'max_depth': 16, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=16, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='random')"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df = df.drop(columns = ['F20'])                       # remove the attribute F20 from the data \n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "#'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "in_data = x_norm\n",
    "target = y_smt\n",
    "\n",
    "print(Build_tree.__doc__)\n",
    "Build_tree(in_data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building pruned decision tree with 'mean imputation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Average Accuracy of the model: 0.675\n",
      "Best parameters: {'ccp_alpha': 0.003125, 'criterion': 'gini', 'max_depth': 13, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.003125, class_weight=None, criterion='gini',\n",
       "                       max_depth=13, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='random')"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.mean(), inplace=True)              # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "print(Build_tree.__doc__)\n",
    "Build_tree(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building pruned decision tree with 'median imputation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Average Accuracy of the model: 0.6729166666666666\n",
      "Best parameters: {'ccp_alpha': 0.003125, 'criterion': 'gini', 'max_depth': 19, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.003125, class_weight=None, criterion='gini',\n",
       "                       max_depth=19, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='random')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.median(), inplace=True)            # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "print(Build_tree.__doc__)\n",
    "Build_tree(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building pruned decision tree with iterative imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Average Accuracy of the model: 0.6833333333333333\n",
      "Best parameters: {'ccp_alpha': 0.006128625472887766, 'criterion': 'gini', 'max_depth': 13, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.006128625472887766, class_weight=None,\n",
       "                       criterion='gini', max_depth=13, max_features=None,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=42,\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "imp = IterativeImputer(max_iter= 10, random_state= 42)  # iterative imputer  https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "x = imp.fit_transform(df.values)                      # select feature to input to the classifier\n",
    "x = pd.DataFrame(x).drop(columns = [20])              # output to the classifier\n",
    "y = df.Class\n",
    "                                 \n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "print(Build_tree.__doc__)\n",
    "Build_tree(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building pruned decision tree with 'KNN imputation' k = int(sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Average Accuracy of the model: 0.6875\n",
      "Best parameters: {'ccp_alpha': 0.0037037037037037034, 'criterion': 'gini', 'max_depth': 14, 'splitter': 'random'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0037037037037037034, class_weight=None,\n",
       "                       criterion='gini', max_depth=14, max_features=None,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=42,\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "x = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = x, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "x = pd.DataFrame(x).drop(columns = [20])\n",
    "y = df.Class\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "print(Build_tree.__doc__)\n",
    "Build_tree(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classifier (x,y):\n",
    "    \n",
    "    clf = LogisticRegression(random_state = 42)        \n",
    "    parameter_grid = { 'penalty':['l1','l2','elasticnet','none'],\n",
    "                       'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga' ],\n",
    "                       'C':[0,0.1,0.5,1,10] }\n",
    "    cross_validation = StratifiedKFold(n_splits=10)                                \n",
    "    grid_search = GridSearchCV(clf, param_grid=parameter_grid, cv=cross_validation, n_jobs = -1) \n",
    "    grid_search.fit(x,y)                                                          \n",
    "    print('Average Accuracy of the model: {}'.format(grid_search.best_score_))  \n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    clf = grid_search.best_estimator_                                              \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### No F20 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.5682397959183673\n",
      "Best parameters: {'C': 0.8, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df = df.drop(columns = ['F20'])                       # remove the attribute F20 from the data \n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "logistic_classifier(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6270833333333333\n",
      "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.mean(), inplace=True)              # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "logistic_classifier(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6333333333333332\n",
      "Best parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.median(), inplace=True)            # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "logistic_classifier(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.8458333333333334\n",
      "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myema\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) # iterative imputer  https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "x = imp.fit_transform(df.values)                      # select feature to input to the classifier\n",
    "x = pd.DataFrame(x).drop(columns = [20])              # output to the classifier\n",
    "y = df.Class\n",
    "                                 \n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "logistic_classifier(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6354166666666666\n",
      "Best parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "x = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = x, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "x = pd.DataFrame(x).drop(columns = [20])\n",
    "y = df.Class\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "logistic_classifier(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes (x,y):\n",
    "    \n",
    "    clf = GaussianNB() \n",
    "    clf.fit(x,y)\n",
    "    score = cross_val_score(clf,x,y,cv = 10)\n",
    "    print('Average Accuracy of the model: {}'.format(np.mean(score)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### No F20 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.5728316326530613\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df = df.drop(columns = ['F20'])                       # remove the attribute F20 from the data \n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "NaiveBayes(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.5604166666666667\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.mean(), inplace=True)              # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "NaiveBayes(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.5645833333333333\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.median(), inplace=True)            # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "NaiveBayes(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.58125\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) # iterative imputer  https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "x = imp.fit_transform(df.values)                      # select feature to input to the classifier\n",
    "x = pd.DataFrame(x).drop(columns = [20])              # output to the classifier\n",
    "y = df.Class\n",
    "                                 \n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "NaiveBayes(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.5583333333333333\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "x = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = x, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "x = pd.DataFrame(x).drop(columns = [20])\n",
    "y = df.Class\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "NaiveBayes(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_(x,y):\n",
    "    clf = svm.SVC (random_state = 42)        \n",
    "    parameter_grid = { 'C':[2**-5,2**-3,2**-1,2**1,2**3,2**5,2**7,2**9,2**11,2**13,2**15],\n",
    "                       'gamma':[2**15,2**13,2**11,2**9,2**7,2**5,2**3,2**1,2**-1,2**-3,2**-5],\n",
    "                       'kernel':['linear','poly','rbf','sigmoid'] }\n",
    "    cross_validation = StratifiedKFold(n_splits=10)                                \n",
    "    grid_search = GridSearchCV(clf, param_grid=parameter_grid, cv=cross_validation, n_jobs = -1) \n",
    "    grid_search.fit(x,y)                                                          \n",
    "    print('Average Accuracy of the model: {}'.format(grid_search.best_score_))  \n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    clf = grid_search.best_estimator_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### No F20 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.7386479591836734\n",
      "Best parameters: {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df = df.drop(columns = ['F20'])                       # remove the attribute F20 from the data \n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "svm_(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.75625\n",
      "Best parameters: {'C': 512, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.mean(), inplace=True)              # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "svm_(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.7562499999999999\n",
      "Best parameters: {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.median(), inplace=True)            # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "svm_(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.8583333333333332\n",
      "Best parameters: {'C': 512, 'gamma': 0.03125, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) # iterative imputer  https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "x = imp.fit_transform(df.values)                      # select feature to input to the classifier\n",
    "x = pd.DataFrame(x).drop(columns = [20])              # output to the classifier\n",
    "y = df.Class\n",
    "                                 \n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "svm_(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.7520833333333333\n",
      "Best parameters: {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "x = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = x, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "x = pd.DataFrame(x).drop(columns = [20])\n",
    "y = df.Class\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "svm_(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(x,y):\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_jobs = -1)  \n",
    "    k_range = range(1, 31)\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    parameter_grid =  {'n_neighbors': k_range,'weights': weight_options}\n",
    "    cross_validation = StratifiedKFold(n_splits=10)                                \n",
    "    grid_search = GridSearchCV(clf, param_grid=parameter_grid, cv=cross_validation, n_jobs = -1) \n",
    "    grid_search.fit(x,y) \n",
    "    print('Average Accuracy of the model: {}'.format(grid_search.best_score_))  \n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    clf = grid_search.best_estimator_  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### No F20 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.647236394557823\n",
      "Best parameters: {'n_neighbors': 4, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df = df.drop(columns = ['F20'])                       # remove the attribute F20 from the data \n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "KNN(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6395833333333332\n",
      "Best parameters: {'n_neighbors': 4, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.mean(), inplace=True)              # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "KNN(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6375\n",
      "Best parameters: {'n_neighbors': 4, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "df.fillna(data.F20.median(), inplace=True)            # replace all the NaN values in F20 feautre with the mean of the F20 Feature\n",
    "x = df.drop(columns=['Class'])                        # select all attributes except class as input to the classifier\n",
    "y = df.Class                                          # select Class as output to the classifier\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "KNN(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6791666666666666\n",
      "Best parameters: {'n_neighbors': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()                                      # create new dataframe from the original data for preprocessing     \n",
    "imp = IterativeImputer(max_iter=10, random_state= 42) # iterative imputer  https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "x = imp.fit_transform(df.values)                      # select feature to input to the classifier\n",
    "x = pd.DataFrame(x).drop(columns = [20])              # output to the classifier\n",
    "y = df.Class\n",
    "                                 \n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "KNN(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy of the model: 0.6770833333333333\n",
      "Best parameters: {'n_neighbors': 4, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "x = int(math.sqrt(df.F20.count()))\n",
    "imputer = KNNImputer(n_neighbors = x, weights = 'distance')\n",
    "x = imputer.fit_transform(df.values)\n",
    "x = pd.DataFrame(x).drop(columns = [20])\n",
    "y = df.Class\n",
    "\n",
    "''' using SMOTE-Tomek method to aritifically generate new data\n",
    "    so that the data is not skewed towards one class '''\n",
    "\n",
    "smt = SMOTETomek(random_state = 42)                   # fixing random state for reproducibility of the model\n",
    "X_smt, y_smt = smt.fit_sample(x, y) \n",
    "\n",
    "'Normalise the data between 0 and 1'\n",
    "x_norm = X_smt.apply(lambda x: (x-x.min())/(x.max()-x.min()),axis = 0)\n",
    "\n",
    "x = x_norm\n",
    "y = y_smt\n",
    "\n",
    "KNN(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
